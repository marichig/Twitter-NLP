{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Script_Processing.tweet_collection_wrapper import TweetCollector\n",
    "from Script_Processing.tweet_io import TweetDataConverter\n",
    "import datetime\n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_anchor = [\"(covid OR coronavirus OR covid19)\"]\n",
    "\n",
    "keywords = [\"(hydroxychloroquine OR plaquenil)\"] ## fill in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = []\n",
    "for words in itertools.product(covid_anchor, keywords):\n",
    "    queries.append(\" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Start/End dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_date_tuple(start_month, start_day, start_year, end_month, end_day, end_year):\n",
    "    return (datetime.datetime(start_year, start_month, start_day, 0, tzinfo = datetime.timezone(datetime.timedelta(hours = 0))),\n",
    "      datetime.datetime(end_year, end_month, end_day, 0, tzinfo = datetime.timezone(datetime.timedelta(hours = 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-03 00:00:00+00:00 2020-09-07 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "start_date, end_date = get_search_date_tuple(9,3, 2020, 9,7,2020)\n",
    "print(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \n",
    "consumer_secret = \n",
    "access_key = \n",
    "access_secret = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = TweetCollector(consumer_key, consumer_secret, access_key, access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse collecting for (covid OR coronavirus OR covid19) (hydroxychloroquine OR plaquenil)\n",
      "Collected 95 from 2020-09-06-19-21 GMT to 2020-09-07-00-00 GMT for query: (covid OR coronavirus OR covid19) (hydroxychloroquine OR plaquenil)\n",
      "Collected 80 from 2020-09-06-16-37 GMT to 2020-09-06-19-21 GMT for query: (covid OR coronavirus OR covid19) (hydroxychloroquine OR plaquenil)\n",
      "Collected 83 from 2020-09-06-14-44 GMT to 2020-09-06-16-37 GMT for query: (covid OR coronavirus OR covid19) (hydroxychloroquine OR plaquenil)\n",
      "Uh-oh, error:\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/search/tweets.json?q=%28covid+OR+coronavirus+OR+covid19%29+%28hydroxychloroquine+OR+plaquenil%29+-filter%3Aretweets+lang%3Aen+until%3A1599403488+since%3A1599091200&tweet_mode=extended&lang=en&count=100 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f9a14d4b8d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n"
     ]
    }
   ],
   "source": [
    "result, log = collector.reverse_chronological_collection(queries, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Tweet Jsons:\n",
    "Might wanna set up a local folder to store logs and the tweet jsons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector.save_tweets_jsons(folder+\"tweet_jsons\")\n",
    "collector.save_logs(folder+\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tweets into a Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframes are used for keeping only the relevant tweet attributes and working with the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"tmp/\"\n",
    "\n",
    "tweet_jsons = json.load(open(folder + \"tweet_jsons.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = TweetDataConverter(tweet_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate tweets = 0\n"
     ]
    }
   ],
   "source": [
    "df = converter.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9726, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status.full_text</th>\n",
       "      <th>status.created_at</th>\n",
       "      <th>status.id_str</th>\n",
       "      <th>status.quoted_status_id_str</th>\n",
       "      <th>status.quoted_status</th>\n",
       "      <th>status.in_reply_to_status_id_str</th>\n",
       "      <th>status.in_reply_to_user_id_str</th>\n",
       "      <th>status.retweet_count</th>\n",
       "      <th>status.favorite_count</th>\n",
       "      <th>status.entities</th>\n",
       "      <th>...</th>\n",
       "      <th>author.id_str</th>\n",
       "      <th>author.name</th>\n",
       "      <th>author.description</th>\n",
       "      <th>author.location</th>\n",
       "      <th>author.verified</th>\n",
       "      <th>author.followers_count</th>\n",
       "      <th>author.friends_count</th>\n",
       "      <th>author.listed_count</th>\n",
       "      <th>author.favourites_count</th>\n",
       "      <th>author.statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@NikolovScience Background: https://t.co/8DHdq...</td>\n",
       "      <td>2020-08-19 08:10:00+00:00</td>\n",
       "      <td>1295996421699756033</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1295927472450543616</td>\n",
       "      <td>884455440293269505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>...</td>\n",
       "      <td>58244415</td>\n",
       "      <td>Hans-Petter Bekeng</td>\n",
       "      <td>Human Being @ Planet Earth. Thinker and Ponder...</td>\n",
       "      <td>Planet Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>2729</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>7623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@stonecold2050 Trump asked Pillow Guy to bring...</td>\n",
       "      <td>2020-08-19 08:10:40+00:00</td>\n",
       "      <td>1295996591401205760</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1295925220205682688</td>\n",
       "      <td>780955609394884608</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>...</td>\n",
       "      <td>864868527249010689</td>\n",
       "      <td>I'm an Extremely Stable Genius 2!üåäüåäüåä</td>\n",
       "      <td>I care about my country. I want to leave it be...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>5087</td>\n",
       "      <td>5550</td>\n",
       "      <td>4</td>\n",
       "      <td>83970</td>\n",
       "      <td>66405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@mungojelly Have you not noticed that you are ...</td>\n",
       "      <td>2020-08-19 08:12:00+00:00</td>\n",
       "      <td>1295996926056435712</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1295940662563606529</td>\n",
       "      <td>5488202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>...</td>\n",
       "      <td>21335196</td>\n",
       "      <td>Ruth Heasman üå∑ü¶öüêâ</td>\n",
       "      <td>Anti-authoritarian, Business owner, Biohacker ...</td>\n",
       "      <td>england</td>\n",
       "      <td>False</td>\n",
       "      <td>1778</td>\n",
       "      <td>3821</td>\n",
       "      <td>28</td>\n",
       "      <td>34983</td>\n",
       "      <td>15047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@guardian The media is very reliable at not le...</td>\n",
       "      <td>2020-08-19 08:12:57+00:00</td>\n",
       "      <td>1295997167526645760</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1295987751809175555</td>\n",
       "      <td>87818409</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'hashtags': [{'text': 'Covid_19', 'indices': ...</td>\n",
       "      <td>...</td>\n",
       "      <td>198522559</td>\n",
       "      <td>Celio</td>\n",
       "      <td>Randomly opinionated by default, don't take it...</td>\n",
       "      <td>üåç</td>\n",
       "      <td>False</td>\n",
       "      <td>735</td>\n",
       "      <td>634</td>\n",
       "      <td>11</td>\n",
       "      <td>10109</td>\n",
       "      <td>13537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Cameron_Davis86 @jshell9985 @Itsyab0y04 @stil...</td>\n",
       "      <td>2020-08-19 08:13:45+00:00</td>\n",
       "      <td>1295997365581688832</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1295905899031203841</td>\n",
       "      <td>828346273862410243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hashtags': [{'text': 'HCQ', 'indices': [119,...</td>\n",
       "      <td>...</td>\n",
       "      <td>2706445465</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>F√ºr #Menschenrechte und #Rechtsstaatlichkeit. ...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>114</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>7833</td>\n",
       "      <td>14758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    status.full_text  \\\n",
       "0  @NikolovScience Background: https://t.co/8DHdq...   \n",
       "1  @stonecold2050 Trump asked Pillow Guy to bring...   \n",
       "2  @mungojelly Have you not noticed that you are ...   \n",
       "3  @guardian The media is very reliable at not le...   \n",
       "4  @Cameron_Davis86 @jshell9985 @Itsyab0y04 @stil...   \n",
       "\n",
       "          status.created_at        status.id_str status.quoted_status_id_str  \\\n",
       "0 2020-08-19 08:10:00+00:00  1295996421699756033                        None   \n",
       "1 2020-08-19 08:10:40+00:00  1295996591401205760                        None   \n",
       "2 2020-08-19 08:12:00+00:00  1295996926056435712                        None   \n",
       "3 2020-08-19 08:12:57+00:00  1295997167526645760                        None   \n",
       "4 2020-08-19 08:13:45+00:00  1295997365581688832                        None   \n",
       "\n",
       "  status.quoted_status status.in_reply_to_status_id_str  \\\n",
       "0                 None              1295927472450543616   \n",
       "1                 None              1295925220205682688   \n",
       "2                 None              1295940662563606529   \n",
       "3                 None              1295987751809175555   \n",
       "4                 None              1295905899031203841   \n",
       "\n",
       "  status.in_reply_to_user_id_str  status.retweet_count  status.favorite_count  \\\n",
       "0             884455440293269505                     0                      0   \n",
       "1             780955609394884608                     2                      4   \n",
       "2                        5488202                     0                      0   \n",
       "3                       87818409                     1                      1   \n",
       "4             828346273862410243                     0                      0   \n",
       "\n",
       "                                     status.entities  ...       author.id_str  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...  ...            58244415   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...  ...  864868527249010689   \n",
       "2  {'hashtags': [], 'symbols': [], 'user_mentions...  ...            21335196   \n",
       "3  {'hashtags': [{'text': 'Covid_19', 'indices': ...  ...           198522559   \n",
       "4  {'hashtags': [{'text': 'HCQ', 'indices': [119,...  ...          2706445465   \n",
       "\n",
       "                            author.name  \\\n",
       "0                    Hans-Petter Bekeng   \n",
       "1  I'm an Extremely Stable Genius 2!üåäüåäüåä   \n",
       "2                      Ruth Heasman üå∑ü¶öüêâ   \n",
       "3                                 Celio   \n",
       "4                                Jordan   \n",
       "\n",
       "                                  author.description author.location  \\\n",
       "0  Human Being @ Planet Earth. Thinker and Ponder...    Planet Earth   \n",
       "1  I care about my country. I want to leave it be...                   \n",
       "2  Anti-authoritarian, Business owner, Biohacker ...         england   \n",
       "3  Randomly opinionated by default, don't take it...               üåç   \n",
       "4  F√ºr #Menschenrechte und #Rechtsstaatlichkeit. ...                   \n",
       "\n",
       "  author.verified author.followers_count  author.friends_count  \\\n",
       "0           False                    256                  2729   \n",
       "1           False                   5087                  5550   \n",
       "2           False                   1778                  3821   \n",
       "3           False                    735                   634   \n",
       "4           False                    114                   628   \n",
       "\n",
       "   author.listed_count  author.favourites_count  author.statuses_count  \n",
       "0                    0                       39                   7623  \n",
       "1                    4                    83970                  66405  \n",
       "2                   28                    34983                  15047  \n",
       "3                   11                    10109                  13537  \n",
       "4                    0                     7833                  14758  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two main steps here:\n",
    "\n",
    "1. Cleaning up the tweet texts - handle things like hashtags, mentions, punctuation, urls, etc.\n",
    "\n",
    "2. Stemming and lemmatizing tweets, which are both ways of mapping a word to some common form (usually it's root/base form)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from Script_Processing.preprocessing_custom import full_preprocess, bio_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9726, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump ID's to test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"study_tweet_ids.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(list(df['status.id_str'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_tweet\"] = df[\"status.full_text\"].apply(full_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_texts(*texts):\n",
    "    to_join = [str(text or ' ') for text in texts]\n",
    "    return \" \".join(to_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- We have no article data, so we don't do this\n",
    "#df[\"clean_article\"] = [\n",
    "#    concat_texts(*x) for x in zip(\n",
    "#        df[\"headlines\"].apply(full_preprocess), df[\"descriptions\"].apply(full_preprocess)\n",
    "#    )\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"clean_tweet_article\"] = [concat_texts(*x) for x in zip(df[\"clean_tweet\"], df[\"clean_article\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"clean_tweet_all_texts\"] = [\n",
    "#    concat_texts(*x) for x in zip(\n",
    "#        df[\"clean_tweet_article\"], df[\"replied_text\"].apply(full_preprocess), df[\"quoted_text\"].apply(full_preprocess)\n",
    "#    )\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_bio\"] = df[\"author.description\"].apply(bio_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9726, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Script_Processing.stem_and_lemmatize import StemLemmaWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_wrapper = StemLemmaWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stemmed_all_texts\"] = df[\"clean_tweet\"].apply(sl_wrapper.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatized_all_texts\"] = df[\"clean_tweet\"].apply(sl_wrapper.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemmatize_stem_all_texts\"] = df[\"clean_tweet\"].apply(sl_wrapper.lemmatize_then_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"temp_df.pkl\"\n",
    "#df.to_pickle(path)\n",
    "import pandas as pd\n",
    "df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starter Code for Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Script_Processing.stop_words_creation as swc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_stopwords = [\"covid19\", \"covid\", \"19\", \"coronavirus\", \"virus\",\n",
    "                    \"hydroxychloroquin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_stop_word_dict = swc.create_and_get_domain_stop_words(domain_stopwords, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Script_Processing.LDA_wrapper import LDA_Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df[\"lemmatize_stem_all_texts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_modeler = LDA_Modeler(corpus, domain_stop_word_dict, \"lemma_stem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: fda treat unlik_effect hospitalis_patient doctor dr_fauci question open_letter trump dr_anthoni\n",
      "Topic 2: life_save 1_2 3_4 medic_librarian risch_4 support_dr document_articl coordin_suppress hcq_az total_crimin\n",
      "Topic 3: think risch dr_harvey convalesc_plasma treatment effect help suppress particip research\n",
      "Topic 4: march fda_revok emerg_author plasma patient clinic_trial treat peopl drug god\n",
      "Topic 5: azithromycin_zinc efficaci treat patient trump plaquenil doctor scandal medic_opinion lab\n",
      "Topic 6: peopl studi trial thousand effect hcq medium_suppress reason treatment work\n",
      "Topic 7: patient prevent treat trump drug doctor cure peopl help life\n",
      "Topic 8: trump kill promot drug patient presid_donald time signific fauci prescrib\n",
      "Topic 9: work doctor peopl drug peopl_die trump like risk_death patient want\n",
      "Topic 10: studi patient low_dose hospit_patient effect treat drug trump infecti_diseas trial\n",
      "Topic 11: trump know work drug rate person doctor fda_approv plasma patient\n",
      "Topic 12: treatment hcq effect studi henri_ford therapi earli life_save health_system death_rate\n",
      "Topic 13: doctor treat stop virus 2 treatment american speak medic fda\n",
      "Topic 14: 4 doctor_worldwid protest_disast medium_sabotag patient physician respect 2_3 100_success dose\n",
      "Topic 15: trump treatment like effect actual death hcq vaccin studi_point expert\n",
      "Topic 16: relat_death polit dr_fauci fda tri true scienc read busi like\n",
      "Topic 17: new_studi patient treatment ivermectin effect medicin forc cure vaccin posit_result\n",
      "Topic 18: look cure countri lie observ_studi trump earli news claim virus\n",
      "Topic 19: hcq work treat fda treatment dr_harvey earli_stage effect death know\n",
      "Topic 20: death work total accord diseas drop trial uganda_popul treatment comment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = lda_modeler.perform_topic_modeling(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
